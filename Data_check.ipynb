{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from openpyxl import load_workbook\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ce90f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 1. Load the data\n",
    "# -------------------------\n",
    "file_path = 'Recipe_checked.xlsx'#you can apply your own data of recipes to replace this one\n",
    "# Read all data\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Standardize ingredient names (based on similarity >= 80)\n",
    "# -------------------------\n",
    "# Get all non-null unique original names\n",
    "unique_names = df['name'].dropna().unique()\n",
    "\n",
    "# Build a mapping dictionary: original name -> standardized name\n",
    "canonical_mapping = {}\n",
    "canonical_list = []\n",
    "\n",
    "for name in unique_names:\n",
    "    found = False\n",
    "    for canon in canonical_list:\n",
    "        if fuzz.ratio(name, canon) >= 80:\n",
    "            canonical_mapping[name] = canon\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        canonical_list.append(name)\n",
    "        canonical_mapping[name] = name\n",
    "\n",
    "# Create a full mapping table\n",
    "mapping_df = pd.DataFrame(list(canonical_mapping.items()), columns=['original_name', 'unified_name'])\n",
    "\n",
    "# Apply the mapping to the original data\n",
    "df['name'] = df['name'].map(canonical_mapping)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Output mappings that differ only due to case or pluralization\n",
    "# -------------------------\n",
    "def is_trivial_change(original, unified):\n",
    "    # Return True if they are the same ignoring case\n",
    "    if original.lower() == unified.lower():\n",
    "        return True\n",
    "    # Return True if they are the same after removing trailing 's' (simple plural handling)\n",
    "    orig = original.lower().rstrip('s')\n",
    "    unif = unified.lower().rstrip('s')\n",
    "    return orig == unif\n",
    "\n",
    "# Filter mappings where names differ only due to case or plural form\n",
    "trivial_mapping = {orig: unif for orig, unif in canonical_mapping.items() \n",
    "                   if orig != unif and is_trivial_change(orig, unif)}\n",
    "trivial_mapping_df = pd.DataFrame(list(trivial_mapping.items()), columns=['original_name', 'unified_name'])\n",
    "display(trivial_mapping_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d872b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original 'gram' values to a new column for reference\n",
    "df['original_gram'] = df['gram']\n",
    "\n",
    "# -------------------------\n",
    "# 4. Process weight information\n",
    "# -------------------------\n",
    "# Attempt to convert the 'gram' column to numeric values (e.g., \"as needed\" will be converted to NaN)\n",
    "df['gram_numeric'] = pd.to_numeric(df['gram'], errors='coerce')\n",
    "\n",
    "# For each standardized ingredient name, calculate the mean of valid numeric 'gram' values\n",
    "group_means = df.groupby('name')['gram_numeric'].transform('mean')\n",
    "\n",
    "def replace_as_needed(row):\n",
    "    # Replace \"as needed\" entries with the average weight of the same ingredient\n",
    "    if isinstance(row['original_gram'], str) and row['original_gram'].strip().lower() == 'as needed':\n",
    "        return group_means[row.name]\n",
    "    else:\n",
    "        return row['gram_numeric']\n",
    "\n",
    "# Apply replacement to the 'gram' column\n",
    "df['gram'] = df.apply(replace_as_needed, axis=1)\n",
    "\n",
    "# Drop the helper column used for numeric conversion\n",
    "df.drop(columns=['gram_numeric'], inplace=True)\n",
    "\n",
    "# -------------------------\n",
    "# 5. Output a check table for replacements of \"as needed\"\n",
    "# -------------------------\n",
    "# Filter records where the original gram value was \"as needed\"\n",
    "df_replaced = df[df['original_gram'].astype(str).strip().str.lower() == 'as needed']\n",
    "# Output a check table including standardized name, original, and replaced gram values\n",
    "print(\"\\nRecords where 'as needed' was replaced with the average:\")\n",
    "display(df_replaced[['name', 'original_gram', 'gram']])\n",
    "\n",
    "# -------------------------\n",
    "# 6. Generate the final DataFrame (keeping all columns, with updated name and gram)\n",
    "# -------------------------\n",
    "final_df = df.copy()\n",
    "\n",
    "display(final_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2124b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# — File paths —\n",
    "fcd_path = \"ASEAN_FCD.xlsx\"\n",
    "input_path = \"Recipe_data.xlsx\"\n",
    "output_path = \"Nutrition_calculated.xlsx\"\n",
    "\n",
    "# — 1. Load data —\n",
    "fcd = pd.read_excel(fcd_path, sheet_name=\"ProcessedTable\", dtype={\"idnutrition\": str})\n",
    "df = pd.read_excel(input_path, sheet_name=\"Sheet1\", dtype={\"idnutrition\": str})\n",
    "\n",
    "# — 2. Use 'gram_adjusted' if available, otherwise fall back to original 'gram' —\n",
    "df[\"gram\"] = pd.to_numeric(\n",
    "    df[\"gram_adjusted\"] if \"gram_adjusted\" in df.columns else df[\"gram\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# — 2b. Drop entire recipes with missing 'gram' or 'idnutrition' (based on 'index') —\n",
    "invalid_index = df[df[\"idnutrition\"].isna()][\"index\"].unique()\n",
    "removed = df[df[\"index\"].isin(invalid_index)].copy()\n",
    "df = df[~df[\"index\"].isin(invalid_index)]\n",
    "\n",
    "# — 3. Merge with nutrition table (keep all rows and track match status) —\n",
    "df = df.merge(fcd, on=\"idnutrition\", how=\"left\", indicator=True)\n",
    "\n",
    "# ✅ Save unmatched ingredient records\n",
    "unmatched = df[df[\"_merge\"] != \"both\"].copy()\n",
    "unmatched = unmatched[[\"index\", \"recipename\", \"name\", \"gram\", \"idnutrition\"]]\n",
    "\n",
    "# ✅ Keep matched records for nutrient calculations\n",
    "df = df[df[\"_merge\"] == \"both\"].drop(columns=\"_merge\")\n",
    "\n",
    "# — 4. Process nutrient columns —\n",
    "skip_cols = {\"code\", \"num\", \"idnutrition\", \"food_description\", \"Source\"}\n",
    "nutrients = [col for col in fcd.columns if col not in skip_cols]\n",
    "for col in nutrients:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0)\n",
    "df[nutrients] = df[nutrients].multiply(df[\"gram\"], axis=0).div(100)\n",
    "\n",
    "# — 5. Calculate total nutrients per recipe —\n",
    "total_nutrients = df.groupby([\"index\", \"recipename\"], as_index=False)[nutrients].sum()\n",
    "\n",
    "# — 6. Extract serving size information —\n",
    "serving_info = (\n",
    "    df[[\"index\", \"recipename\", \"serving\"]]\n",
    "    .drop_duplicates(subset=[\"index\", \"recipename\"])\n",
    "    .assign(serving=lambda d: pd.to_numeric(d[\"serving\"], errors=\"coerce\"))\n",
    ")\n",
    "\n",
    "# — 7. Calculate nutrients per serving —\n",
    "per_serving = total_nutrients.merge(serving_info, on=[\"index\", \"recipename\"])\n",
    "for col in nutrients:\n",
    "    per_serving[col] = per_serving[col] / per_serving[\"serving\"]\n",
    "\n",
    "# — 8. Ingredient-level nutrient contribution —\n",
    "ingredient_contribution = df[[\"index\", \"recipename\", \"name\", \"gram\", \"idnutrition\"] + nutrients]\n",
    "\n",
    "# — 9. Save results to Excel —\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    total_nutrients.to_excel(writer, sheet_name=\"Total_Nutrition\", index=False)\n",
    "    per_serving.to_excel(writer, sheet_name=\"Per_Serving_Nutrition\", index=False)\n",
    "    ingredient_contribution.to_excel(writer, sheet_name=\"Ingredient_Nutrient_Contribution\", index=False)\n",
    "    unmatched.to_excel(writer, sheet_name=\"Unmatched_Ingredients\", index=False)\n",
    "    removed.to_excel(writer, sheet_name=\"Removed_Recipes\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Path settings ---\n",
    "idea_folder = \"/path for IDEA database\"\n",
    "carbon_output_path = \"/new file for output\"\n",
    "\n",
    "# Assumption: the DataFrame `df` already contains the following columns:\n",
    "# [\"index\", \"recipename\", \"name\", \"gram\", \"idnutrition\", \"IDEA製品コード\", \"countrycode\", \"serving\"]\n",
    "\n",
    "# --- 1. Get all unique country codes present in the data ---\n",
    "countries = df['countrycode'].dropna().unique()\n",
    "idea_data = {}\n",
    "\n",
    "# --- 2. Load country-specific IDEA emission intensity data ---\n",
    "for country in countries:\n",
    "    idea_file = os.path.join(idea_folder, f\"IDEA_v3.3_{country}.xlsx\")\n",
    "    if os.path.exists(idea_file):\n",
    "        idea_df = pd.read_excel(idea_file, sheet_name=\"LCIA結果_GWP\", header=3, index_col=\"IDEA製品コード\")\n",
    "        idea_data[country] = idea_df\n",
    "    else:\n",
    "        print(f\"⚠️ Data for {country} is missing. Will use GLO data as fallback.\")\n",
    "\n",
    "# Load fallback GLO dataset\n",
    "glo_df = pd.read_excel(os.path.join(idea_folder, \"IDEA_v3.3_GLO.xlsx\"), \n",
    "                       sheet_name=\"LCIA結果_GWP\", header=3, index_col=\"IDEA製品コード\")\n",
    "glo_map = glo_df['気候変動 IPCC 2021 GWP 100a'].to_dict()\n",
    "\n",
    "results = []\n",
    "\n",
    "# --- 3. Calculate carbon footprint per recipe, grouped by country ---\n",
    "for country, group_df in df.groupby('countrycode'):\n",
    "    group_df = group_df.copy()\n",
    "    display(group_df)\n",
    "    idea_df = idea_data.get(country, glo_df)\n",
    "    country_suffix = country if country in idea_data else 'GLO'\n",
    "    \n",
    "    # Modify IDEA product code to match country-specific format\n",
    "    group_df['IDEA製品コード_国'] = group_df['IDEA製品コード'].apply(\n",
    "        lambda x: x[:-3] + country_suffix if isinstance(x, str) and len(x) >= 3 else x\n",
    "    )\n",
    "    \n",
    "    # Merge with emission intensity data\n",
    "    group_df = group_df.merge(\n",
    "        idea_df[['気候変動 IPCC 2021 GWP 100a']],\n",
    "        left_on='IDEA製品コード_国',\n",
    "        right_index=True,\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill unmatched records with fallback GLO values\n",
    "    unmatched = group_df['気候変動 IPCC 2021 GWP 100a'].isna()\n",
    "    if unmatched.any():\n",
    "        print(f\"⚠️ {country}: {unmatched.sum()} unmatched records. Using GLO as fallback.\")\n",
    "        group_df.loc[unmatched, 'IDEA製品コード_GLO'] = group_df.loc[unmatched, 'IDEA製品コード'].apply(\n",
    "            lambda x: x[:-3] + 'GLO' if pd.notnull(x) else x\n",
    "        )\n",
    "        group_df.loc[unmatched, '気候変動 IPCC 2021 GWP 100a'] = group_df.loc[unmatched, 'IDEA製品コード_GLO'].map(glo_map)\n",
    "    \n",
    "    # Report any entries still unmatched after fallback\n",
    "    if group_df['気候変動 IPCC 2021 GWP 100a'].isna().any():\n",
    "        unmatched_final = group_df[group_df['気候変動 IPCC 2021 GWP 100a'].isna()][['name', 'IDEA製品コード']]\n",
    "        print(f\"❌ Unmatched records remain in {country}:\")\n",
    "        display(unmatched_final)\n",
    "\n",
    "    # Calculate ingredient-level carbon footprint (in kg CO2-eq)\n",
    "    group_df['ingredient_footprint'] = (group_df['gram'] / 1000) * group_df['気候変動 IPCC 2021 GWP 100a'].fillna(0)\n",
    "\n",
    "    # Aggregate carbon footprint at the recipe level\n",
    "    dish_footprint = group_df.groupby(['index', 'recipename'], as_index=False).agg({\n",
    "        'ingredient_footprint': 'sum',\n",
    "        'serving': 'first',\n",
    "        'countrycode': 'first'\n",
    "    })\n",
    "    \n",
    "    # Compute footprint per serving\n",
    "    dish_footprint['footprint_per_serving'] = dish_footprint['ingredient_footprint'] / dish_footprint['serving']\n",
    "    results.append(dish_footprint)\n",
    "\n",
    "# --- 4. Combine results from all countries ---\n",
    "final_footprint = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# --- 5. Export to Excel ---\n",
    "final_footprint.to_excel(carbon_output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4c01e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "file_path = \"Recipe_Data.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Count the number of dishes by country and dish type\n",
    "country_dish_counts = df.groupby(['country', 'dish type 1']).size().unstack(fill_value=0)\n",
    "\n",
    "# Output the statistics\n",
    "print(\"Number of each dish type per country:\")\n",
    "print(country_dish_counts)\n",
    "\n",
    "# Use the provided color codes\n",
    "color_map = {\n",
    "    'beef': '#E3A967',\n",
    "    'pork': '#EEC97C',\n",
    "    'chicken': '#F7E4BA',\n",
    "    'seafood': '#B0D6D9',\n",
    "    'vegetable': '#7FB2C9',\n",
    "    'other': '#5D88A3'\n",
    "}\n",
    "\n",
    "# Define a fixed dish type order to keep pie chart colors consistent\n",
    "dish_order = ['beef', 'pork', 'chicken', 'seafood', 'vegetable', 'other']\n",
    "\n",
    "# Plot a pie chart for each country\n",
    "for country, row in country_dish_counts.iterrows():\n",
    "    row = row.reindex(dish_order, fill_value=0)\n",
    "    row_nonzero = row[row > 0]  # Only include dish types with non-zero values\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pie(\n",
    "        row_nonzero,\n",
    "        colors=[color_map[d] for d in row_nonzero.index],\n",
    "        startangle=90  # Start from top to make layout cleaner\n",
    "    )\n",
    "    plt.axis('equal')  # Ensure the pie chart is a circle\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{country}_dish_type_1_pie.svg\", format='svg', transparent=True)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116222fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of dishes by country and dish type 2\n",
    "country_dish_counts2 = df.groupby(['country', 'dish type 2']).size().unstack(fill_value=0)\n",
    "\n",
    "# Define the order of dish categories\n",
    "dish_order2 = [\n",
    "    'Beverages/Drinks',\n",
    "    'Condiments/Seasonings/Sauces',\n",
    "    'Meat Dishes',\n",
    "    'Noodle-Based Dishes',\n",
    "    'Others',\n",
    "    'Salads',\n",
    "    'Seafood Dishes',\n",
    "    'Side Dishes/Pickles',\n",
    "    'Snacks/Desserts',\n",
    "    'Soups',\n",
    "    'Vegetarian Dishes'\n",
    "]\n",
    "\n",
    "# Define a custom spectral color palette\n",
    "custom_colors = [\n",
    "    '#9e0142', '#d53e4f', '#f46d43', '#fdae61', '#fee08b',\n",
    "    '#ffffbf', '#e6f598', '#abdda4', '#66c2a5', '#3288bd', '#5e4fa2'\n",
    "]\n",
    "\n",
    "# Create a color mapping dictionary for dish types\n",
    "color_map2 = dict(zip(dish_order2, custom_colors))\n",
    "\n",
    "# Define the output directory for saving pie charts\n",
    "save_dir = \"/Pie chart\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save pie charts for each country's dish type 2 distribution\n",
    "for country, row in country_dish_counts2.iterrows():\n",
    "    row = row.reindex(dish_order2, fill_value=0)\n",
    "    row_nonzero = row[row > 0]\n",
    "    if row_nonzero.empty:\n",
    "        continue\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pie(\n",
    "        row_nonzero,\n",
    "        labels=None,  # Do not display labels\n",
    "        colors=[color_map2[d] for d in row_nonzero.index],\n",
    "        startangle=90,\n",
    "        autopct=None  # Do not display percentages\n",
    "    )\n",
    "\n",
    "#     ax.set_title(country, fontsize=12)  # Optional: add country name as title\n",
    "    plt.axis('equal')  # Keep pie chart circular\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    out_path = os.path.join(save_dir, f\"{country}_dish_type_2_pie.svg\")\n",
    "    plt.savefig(out_path, format='svg', transparent=True)\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
